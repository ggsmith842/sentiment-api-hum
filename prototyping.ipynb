{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rake_nltk import Rake\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchTweets(search_term:str):\n",
    "    load_dotenv()\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?max_results=25&expansions=referenced_tweets.id&tweet.fields=text&query=lang%3Aen%20\"+search_term\n",
    "\n",
    "    payload={}\n",
    "    headers = {\n",
    "    'Authorization': os.getenv('BEARER_TOKEN'),\n",
    "    'Cookie': 'guest_id=v1%3A165292464833657250; guest_id_ads=v1%3A165292464833657250; guest_id_marketing=v1%3A165292464833657250; personalization_id=\"v1_D50leSEsdlQN9nTvwQ6B+g==\"'\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload).json()['includes']['tweets']\n",
    "\n",
    "    tweets = [i['text'] for i in response]\n",
    "\n",
    "\n",
    "    # out_file = open(\"myfile.json\", \"w\") \n",
    "    # json.dump(tweets, out_file, indent = 6) \n",
    "    # out_file.close() \n",
    "    \n",
    "    # with open('myfile.json') as f:\n",
    "    #  data = json.load(f)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = searchTweets(\"Biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was considered a huge offense when Trump did ‘mean tweets’ yet Biden can offend more than half the country with his fascist discourse &amp; it’s considered justifiable. \\nThe double standard is beyond incomprehensible.', 'Has Biden cured cancer yet?', '“Why didn’t Joe Biden unify us??” https://t.co/eeS85fvQvX', 'I can׳t believe ABC, CBS, and NBC all declined to carry President Biden’s speech last night because it was too “political.”\\n\\nI’m too old to remember how they carried every Trump rant since the day he announced his presidential run until his last day in the WH. Shameful!', 'Biden admin’s push for a G7 price cap on Russian oil was strategic thinking aimed at closing off revenue streams for Putin to finance the war in Ukraine — https://t.co/i29IE2KKa1', 'So Elon’s $44B to buy twitter could have ended world hunger but nobody is asking about the $55B+ Biden has sent to ukraine?', 'Biden is the worst President in history. America is going to hell. Crimes have skyrocketed. Biden is letting in so many terrorists from around the world. You wouldn\\'t believe the many \"allahu akbar\" incidents because the corrupt media hides it. Biden loves Pakistan more than USA.', 'Please retweet to help @NikkiHaley understand why Joe Biden calls MAGA Republicans bad people. https://t.co/dkXKk5gIaB', \"@RyanAFournier False.  81 million of us stood in line when we voted for Biden, the only rally that really counted. \\n\\nYou're welcome.\", 'Biden calling half the country “extremists,”while inflation soars, grocery prices rise, and crime skyrockets is not the “unity” that was promised.', 'Since they hate Biden’s policies so much, I fully expect every Republican who qualifies for student loan forgiveness to turn it down.', \"Fun fact: Biden's Ultra Maga speech was on the 89th anniversary of Hitler's Nuremberg Rally September 1, 1933.\", \"Wow guys... Biden created “10 thousand million jobs” since he took office and next he's going to cure cancer.\", '@shadowreaper93 @divinemakyr @julsgars810 @VaushV Okay one at a time here\\n\\nSegregation- While there certainly have been examples of safe spaces being exclusionary, physical “safe spaces” are typically just small places where you can go and not have people be mean to you, which is nice for mental health.', 'MAGA goes all out to prove they’re not Nazis, by doing what? Being Nazis of course…\\nhttps://t.co/0UQ3hhpkjI', '@Friia10 @redman0124 @sariwyn76 @RpsAgainstTrump My mom took the exact same test trump did. \\n\\nFailure means you belong in memory care. \\n\\nTrump bragged about passing it. Nothing to brag about.', '“The\\xa0insurrectionists of Jan. 6\\xa0busted into the Capitol, hit police with fire extinguishers, flagpoles, bats, stun guns and pepper spray; threatened to kill the vice president and tried to overthrow the 2020 election. And now, they want an apology.”\\n\\nhttps://t.co/5fjyuSxGIa', 'Even if Biden is removed, the same corrupt bastards will be running the shit show. \\n\\nWe need a MAGA Red Wave too large to steal.', \"I Think Biden's Speech May Have Backfired On Him A Bit  #PedoHitler https://t.co/KznM9YSbFo\", '@JoeBiden Mr. President Biden, For democracy to work in America, we must protect it worldwide, that means , we can not allow Sisi, Bashar and Putin to kill and imprison their nations including human rights activists', '\"How dare Joe Biden call us fascists!\" https://t.co/N0x0XR5i8v']\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build text pre-processing \n",
    "#would a class for the tweets be smart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_text = re.sub(r'\\b(https?://\\S+)\\b','',text) #remove URLs\n",
    "    clean_text = \" \".join(re.findall('\\w{3,}',clean_text))\n",
    "    word_tokens = word_tokenize(clean_text)\n",
    "    filtered_text = \" \".join([word for word in word_tokens if word not in stop_words])\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = [process_text(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['considered huge offense Trump mean tweets yet Biden offend half country fascist discourse amp considered justifiable The double standard beyond incomprehensible',\n",
       " 'Has Biden cured cancer yet',\n",
       " 'Why Joe Biden unify',\n",
       " 'believe ABC CBS NBC declined carry President Biden speech last night political old remember carried every Trump rant since day announced presidential run last day Shameful',\n",
       " 'Biden admin push price cap Russian oil strategic thinking aimed closing revenue streams Putin finance war Ukraine',\n",
       " 'Elon 44B buy twitter could ended world hunger nobody asking 55B Biden sent ukraine',\n",
       " 'Biden worst President history America going hell Crimes skyrocketed Biden letting many terrorists around world You believe many allahu akbar incidents corrupt media hides Biden loves Pakistan USA',\n",
       " 'Please retweet help NikkiHaley understand Joe Biden calls MAGA Republicans bad people',\n",
       " 'RyanAFournier False million stood line voted Biden rally really counted You welcome',\n",
       " 'Biden calling half country extremists inflation soars grocery prices rise crime skyrockets unity promised',\n",
       " 'Since hate Biden policies much fully expect every Republican qualifies student loan forgiveness turn',\n",
       " 'Fun fact Biden Ultra Maga speech 89th anniversary Hitler Nuremberg Rally September 1933',\n",
       " 'Wow guys Biden created thousand million jobs since took office next going cure cancer',\n",
       " 'shadowreaper93 divinemakyr julsgars810 VaushV Okay one time Segregation While certainly examples safe spaces exclusionary physical safe spaces typically small places people mean nice mental health',\n",
       " 'MAGA goes prove Nazis Being Nazis course',\n",
       " 'Friia10 redman0124 sariwyn76 RpsAgainstTrump mom took exact test trump Failure means belong memory care Trump bragged passing Nothing brag',\n",
       " 'The insurrectionists Jan busted Capitol hit police fire extinguishers flagpoles bats stun guns pepper spray threatened kill vice president tried overthrow 2020 election And want apology',\n",
       " 'Even Biden removed corrupt bastards running shit show need MAGA Red Wave large steal',\n",
       " 'Think Biden Speech May Have Backfired Him Bit PedoHitler',\n",
       " 'JoeBiden President Biden For democracy work America must protect worldwide means allow Sisi Bashar Putin kill imprison nations including human rights activists',\n",
       " 'How dare Joe Biden call fascists']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get keywords\n",
    "clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from math import floor\n",
    "\n",
    "def get_keywords(sentences: list):\n",
    "    '''\n",
    "    Given a list of strings, return the top keywords that are at least 4 letters long\n",
    "    '''        \n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_sentences(sentences)\n",
    "    r.get_ranked_phrases_with_scores()\n",
    "    keywords = r.get_ranked_phrases()[0].split(\" \")\n",
    "    avg_keyword_len = floor(mean([len(i) for i in keywords]))\n",
    "    best_keywords = [i for i in keywords if len(i)>avg_keyword_len and len(i)>3]\n",
    "    return best_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['believe',\n",
       " 'declined',\n",
       " 'president',\n",
       " 'speech',\n",
       " 'political',\n",
       " 'remember',\n",
       " 'carried',\n",
       " 'announced',\n",
       " 'presidential',\n",
       " 'shameful']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keywords(clean_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', -0.22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get sentiment\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "def get_avg_sentiment(tweets):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    term_sentiment = round(mean([sia.polarity_scores(tweet)['compound'] for tweet in tweets ]),2)\n",
    "\n",
    "    if term_sentiment < -0.33:\n",
    "        return (\"negative\", term_sentiment)\n",
    "    elif term_sentiment > 0.33:\n",
    "        return (\"positive\", term_sentiment)\n",
    "    else:\n",
    "        return (\"neutral\",term_sentiment)\n",
    "\n",
    "get_avg_sentiment(clean_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['believe',\n",
       " 'president',\n",
       " 'speech',\n",
       " 'political',\n",
       " 'remember',\n",
       " 'announced',\n",
       " 'presidential',\n",
       " 'shameful']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = get_keywords(clean_tweets,)\n",
    "\n",
    "tag=pos_tag(keywords)\n",
    "\n",
    "[i[0] for i in tag if i[1] not in ['VBG','VBD','RB','PDT','POS','WDT','WP','WRB',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_trends():\n",
    "  url = \"https://api.twitter.com/1.1/trends/place.json?id=23424977\"\n",
    "  headers = {\n",
    "  'Authorization': os.getenv(\"BEARER_TOKEN\"),\n",
    "  'Cookie': 'guest_id=v1%3A165292464833657250; guest_id_ads=v1%3A165292464833657250; guest_id_marketing=v1%3A165292464833657250; personalization_id=\"v1_D50leSEsdlQN9nTvwQ6B+g==\"'\n",
    "  }\n",
    "\n",
    "  try:\n",
    "    response = requests.request(\"GET\",url,headers=headers).json()[0]['trends']\n",
    "    response.sort(key=lambda x:0 if x[\"tweet_volume\"] is None else x[\"tweet_volume\"],reverse=True)\n",
    "    results = [trend['name'] for trend in response]\n",
    "    return results\n",
    "  except Exception as e:\n",
    "    error_message = f\"An error occured in call_trends(): {e}\"\n",
    "    return error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bam Bam', '#WWECastle', '#UFCParis', 'Roman', 'Gane', 'Gane', 'Drew', '#taylorhawkinstribute', 'Wilbur', 'Utah', 'Oregon', 'Oregon', 'Iowa', 'Arizona', 'My Hero', 'Seth', 'Gunther', 'Sheamus', 'Arkansas', 'App State', 'Dave Grohl', '#GoDawgs', 'Whittaker', 'Bo Nix', 'Broken Dreams', 'Tyson Fury', 'Buckley', 'Vettori', 'NC State', 'Cincinnati', '#OREvsUGA', 'Stetson Bennett', 'North Dakota', 'Bobby Knuckles', 'Anthony Grant', 'UTSA', 'Auburn', 'Ladd McConkey', 'PAC 12', 'Dan Lanning', 'Shane Hawkins', 'UTEP', 'UCLA', 'SDSU', 'Ty Thompson', 'Cincy', 'Ben Bryant', 'East Carolina', 'Darnell Washington', 'Caleb Williams']\n"
     ]
    }
   ],
   "source": [
    "x = call_trends()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(term):\n",
    "\ttry:\t\n",
    "\t\tif term:\n",
    "\t\t\traw_results = searchTweets(term)\n",
    "\t\t\tprocessed_results = [process_text(tweet) for tweet in raw_results]\n",
    "\n",
    "\t\t\tsentiment = get_avg_sentiment(processed_results)\t\n",
    "\t\t\tkeywords = get_keywords(processed_results)\n",
    "\n",
    "\t\t\tresults = {\"sentiment\" : sentiment[0],\n",
    "\t\t\t\t\"score\": sentiment[1],\n",
    "\t\t\t\t\"keywords\":keywords\n",
    "\t\t\t}\n",
    "\t\t\treturn {\"sentiment\" : results}\n",
    "\t\telse:\n",
    "\t\t\treturn {\"message\":\"nothing to seach\"}\n",
    "\texcept Exception as e:\n",
    "\t\treturn {\"error\":e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(\"Linux\")['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neutral',\n",
       " 'score': 0.08,\n",
       " 'keywords': ['dataanalyst',\n",
       "  'machinelearning',\n",
       "  'datascience',\n",
       "  'cybersecurity',\n",
       "  'analytics',\n",
       "  'tensorflow',\n",
       "  'javascript',\n",
       "  'cloudcomputing',\n",
       "  'serverless',\n",
       "  'datascientist',\n",
       "  'programming',\n",
       "  '100daysofcode']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fastvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d7811bf6c5bfbaede772596fcb0508576ecab4549c8aa3c780d738ece0b383a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
